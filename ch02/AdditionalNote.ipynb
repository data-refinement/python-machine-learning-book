{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Additionalnote\" data-toc-modified-id=\"Additionalnote-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Additionalnote</a></div><div class=\"lev2 toc-item\"><a href=\"#Additional-Note-(1)\" data-toc-modified-id=\"Additional-Note-(1)-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Additional Note (1)</a></div><div class=\"lev3 toc-item\"><a href=\"#英語\" data-toc-modified-id=\"英語-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>英語</a></div><div class=\"lev3 toc-item\"><a href=\"#日本語訳\" data-toc-modified-id=\"日本語訳-112\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>日本語訳</a></div><div class=\"lev3 toc-item\"><a href=\"#解釈\" data-toc-modified-id=\"解釈-113\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>解釈</a></div><div class=\"lev2 toc-item\"><a href=\"#Additional-Note(2)\" data-toc-modified-id=\"Additional-Note(2)-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Additional Note(2)</a></div><div class=\"lev3 toc-item\"><a href=\"#英語\" data-toc-modified-id=\"英語-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>英語</a></div><div class=\"lev3 toc-item\"><a href=\"#日本語訳\" data-toc-modified-id=\"日本語訳-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>日本語訳</a></div><div class=\"lev2 toc-item\"><a href=\"#Additional-Note(3)\" data-toc-modified-id=\"Additional-Note(3)-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Additional Note(3)</a></div><div class=\"lev3 toc-item\"><a href=\"#英語\" data-toc-modified-id=\"英語-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>英語</a></div><div class=\"lev3 toc-item\"><a href=\"#日本語訳\" data-toc-modified-id=\"日本語訳-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>日本語訳</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python machine learning bookのレポジトリの２章のAdditionalnoteを訳してみました。  \n",
    "https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb\n",
    "\n",
    "- Addtional Note1\n",
    "    - 重みの初期値について\n",
    "- Additional Note2\n",
    "    - self.w[0]を加えているコードについての説明\n",
    "- Additional Note3\n",
    "    - サンプルのシャップルについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additionalnote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Note (1)\n",
    "\n",
    "### 英語\n",
    "Please note that the learning rate η (eta) only has an effect on the classification outcome  if the weights are initialized to non-zero values.  \n",
    "If all the weights are initialized to 0, the learning rate parameter eta affects only the scale of the weight vector but not its direction.  \n",
    "To have the learning rate influence the classification outcome, the weights need to be initialized to non-zero values.  \n",
    "The respective lines in the code that need to be changed to accomplish that are highlighted on below:  \n",
    "\n",
    "```python\n",
    "   def __init__(self, eta=0.01, n_iter=50, random_seed=1): # add random_seed=1\n",
    "        ...\n",
    "        self.random_seed = random_seed # add this line\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        ...\n",
    "        # self.w_ = np.zeros(1 + X.shape[1]) ## remove this line\n",
    "        rgen = np.random.RandomState(self.random_seed) # add this line\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1]) # add this line\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日本語訳\n",
    "\n",
    "学習率η（eta）は、重みがゼロ以外の値に初期化されている場合にのみ、分類結果に影響を与えることに注意してください。\n",
    "すべての重みが0に初期化されると、学習率パラメータηは重みベクトルの大きさにのみ影響を及ぼし、方向に影響を及ぼしません。  \n",
    "学習率が分類結果に影響するようにするには、ウェイトを0以外の値に初期化する必要があります。  \n",
    "変更する必要があるコードの各行は、以下で強調表示されています：\n",
    "\n",
    "\n",
    "```python\n",
    "   def __init__(self, eta=0.01, n_iter=50, random_seed=1): # add random_seed=1\n",
    "        ...\n",
    "        self.random_seed = random_seed # add this line # シードの設定\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        ...\n",
    "        # self.w_ = np.zeros(1 + X.shape[1]) ## remove this line\n",
    "        rgen = np.random.RandomState(self.random_seed) # add this line \n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1]) # add this line # 重みの設定,Xの列数 + 1の長さ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解釈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重みが全てゼロだと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(z) = 0$となってしまい、常に$\\phi(z) = 1$となってしまう。  \n",
    "そのため、重みの更新結果は入力されたサンプルのクラスにのみ影響を受けることとなる。  \n",
    "そのため、重みは、0以外にするのが望ましい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Note(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英語 \n",
    "I received a note by a reader who asked about the net input function:\n",
    "\n",
    ">On page 27, you describe the code.\n",
    "\n",
    "> the net_input method simply calculates the vector product wTx\n",
    "However, there is more than a simple vector product in the code:\n",
    "\n",
    "> def net_input(self, X):  \n",
    "    \"\"\"Calculate net input\"\"\"  \n",
    "    return np.dot(X, self.w_[1:]) + self.w_[0]  \n",
    "   \n",
    "> In addition to the dot product, there is an addition. The text does not mention anything about what is this + self.w_[0]\n",
    "> Can you (or anyone) explain why that's there?\n",
    "\n",
    "-------\n",
    "\n",
    "Sorry that I went over that so briefly. The `self.w_[0]` is basically the \"threshold\" or so-called \"bias unit.\" I simply included the bias unit in the weight vector, which makes the math part easier, but on the other hand, it may make the code more confusing as you mentioned.\n",
    "\n",
    "\n",
    "\n",
    "Let's say we have a 3x2 dimensional dataset `X` (3 training samples with 2 features). Also, let's just assume we have a weight `2` for feature 1 and a weight `3` for feature 2, and we set the bias unit to `4`. \n",
    "\n",
    "```\n",
    "import numpy as np\n",
    ">>> bias = 4.\n",
    ">>> X = np.array([[2., 3.], \n",
    "...              [4., 5.], \n",
    "...              [6., 7.]])\n",
    ">>> w = np.array([bias, 2., 3.])\n",
    "```\n",
    "\n",
    "In order to match the mathematical notation, we would have to add a vector of 1s to compute the dot-product:\n",
    "\n",
    "```\n",
    ">>> ones = np.ones((X.shape[0], 1))\n",
    ">>> X_with1 = np.hstack((ones, X))\n",
    ">>> X_with1\n",
    ">>> np.dot(X_with1, w)\n",
    "array([ 17.,  27.,  37.])\n",
    "```\n",
    "\n",
    "However, I thought that adding a vector of 1s to the training array each time we want to make a prediction would be fairly inefficient. So, instead, we can just \"add\" the bias unit (`w[0]`) to the do product (it's equivalent, since `1.0 * w_0 = w_0`:\n",
    "\n",
    "```\n",
    ">>> np.dot(X, w[1:]) + w[0] \n",
    "array([ 17.,  27.,  37.])\n",
    "```\n",
    "\n",
    "Maybe it is helpful to walk through the matrix-vector multiplication by hand. E.g.,\n",
    "\n",
    "```\n",
    "| 1  2  3 |   | 4 |   | 1*4 + 2*2 + 3*3 |   | 17 |\n",
    "| 1  4  5 | x | 2 | = | 1*4 + 4*2 + 5*3 | = | 27 |\n",
    "| 1  6  7 |   | 3 |   | 1*4 + 6*2 + 7*3 |   | 37 |\n",
    "```\n",
    "\n",
    "which is the same as\n",
    "\n",
    "```\n",
    "| 2  3 |                  | 2*2 + 3*3 |          | 13 + bias |   | 17 |\n",
    "| 4  5 | x | 2 | + bias = | 4*2 + 5*3 | + bias = | 23 + bias | = | 27 |\n",
    "| 6  7 |   | 3 |          | 6*2 + 7*3 |          | 33 + bias |   | 37 |\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日本語訳\n",
    "\n",
    "net_input　メソッドについて、読者から質問を受けた。\n",
    "\n",
    "> 27ページのコードについて\n",
    "\n",
    "> net_input メソッドは単にベクトルのドット積 $w^T x$を計算している。  \n",
    "しかしながら、コードでは、ベクトルのドット積以上のコードとなっている。（self.w_[0]が加えられているが説明がない）  \n",
    "是非説明をお願いしたい。\n",
    "\n",
    "> def net_input(self, X):  \n",
    "    \"\"\"Calculate net input\"\"\"  \n",
    "    return np.dot(X, self.w_[1:]) + self.w_[0]  \n",
    "   \n",
    "> In addition to the dot product, there is an addition. The text does not mention anything about what is this + self.w_[0]\n",
    "> Can you (or anyone) explain why that's there?\n",
    "\n",
    "-------\n",
    "\n",
    "self.w_[0]は閾値とかバイアスと呼ばれる。  \n",
    "本では、単純に重みベクトルににバイアスを含めましたが、これは数学的な部分を簡単にするが、一方で、質問のようにコードを混乱させるかもしれません。\n",
    "\n",
    "\n",
    "3行×2列のデータセット「X」（2つの特徴量を有する3つのトレーニングサンプル）があるとしよう。\n",
    "また、w_1（特徴量１のウェイト）= 2、w_2（特徴量2のウェイト）= 3 w_0（バイアス）= 4に設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias = 4.\n",
    "X = np.array([[2.,3.],\n",
    "             [4.,5.],\n",
    "             [6.,7.]])\n",
    "w = np.array([bias,2.,3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 1.,  4.,  5.],\n",
       "       [ 1.,  6.,  7.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_with1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.,  27.,  37.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数学的表記法と一致させるためには、ドット積を計算するために1のベクトルを追加する必要があります。\n",
    "ones = np.ones((X.shape[0], 1)) # 3*1の列ベクトル\n",
    "X_with1 = np.hstack((ones, X)) # 3*3の行列（Xの左端にonesを追加）\n",
    "np.dot(X_with1,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.,  27.,  37.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# しかし、予測をする毎に、トレーニング行列に１ベクトルを加えるというのはかなり非効率です。\n",
    "# その替わりに、ベクトルのドット積に単にバイアス（'w[0]')を加えることができる。（これは1.0*w_0 = w_0なので同等です。）\n",
    "\n",
    "np.dot(X,w[1:]) + w[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おそらく、手で計算してみるとわかります。例えば、以下の１と２の計算は同等です。\n",
    "\n",
    "1.\n",
    "```\n",
    "| 1  2  3 |   | 4 |   | 1*4 + 2*2 + 3*3 |   | 17 |\n",
    "| 1  4  5 | x | 2 | = | 1*4 + 4*2 + 5*3 | = | 27 |\n",
    "| 1  6  7 |   | 3 |   | 1*4 + 6*2 + 7*3 |   | 37 |\n",
    "```\n",
    "\n",
    "2.\n",
    "```\n",
    "| 2  3 |           　　 　　 　　 　    | 2*2 + 3*3 | 　　　　　    　     | 13 + bias | 　  | 17 |\n",
    "| 4  5 | x | 2 | + bias = | 4*2 + 5*3 | + bias = | 23 + bias | = | 27 |\n",
    "| 6  7 |   | 3 |     　　 　　 　　   | 6*2 + 7*3 |      　　　　　    | 33 + bias |  　　 | 37 |\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Note(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英語"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity at this point, we don't talk about shuffling at this point; I wanted to introduce concepts incrementally so that it's not too overwhelming all at once. Since a reader asked me about this, I wanted to add a note about shuffling, which you may want to use if you are using a Perceptron in practice. I borrowed the code from the `AdalineSGD` section below to modify the Perceptron algorithm accordingly (new lines are marked by trailing \"`# new`\" inline comment):\n",
    "\n",
    "```python\n",
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "        Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "        Passes over the training dataset.\n",
    "    shuffle : bool (default: True)\n",
    "        Shuffles training data every epoch if True to prevent cycles.\n",
    "    random_state : int (default: None)\n",
    "        Set random state for shuffling and initializing the weights.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "        Weights after fitting.\n",
    "    errors_ : list\n",
    "        Number of misclassifications in every epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10,\n",
    "                 shuffle=True, random_state=None):  # new\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.shuffle = shuffle  # new\n",
    "        if random_state:  # new\n",
    "            np.random.seed(random_state)  # new\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            if self.shuffle:  # new\n",
    "                X, y = self._shuffle(X, y)  # new\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def _shuffle(self, X, y):  # new\n",
    "        \"\"\"Shuffle training data\"\"\"  # new\n",
    "        r = np.random.permutation(len(y))  # new\n",
    "        return X[r], y[r]  # new\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日本語訳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡単のために、サンプルのシャッフルについては、この段階では触れていません。  \n",
    "一気にコンセンプトを導入するのではなく、段階で気に導入したかったためです。  \n",
    "読者から質問があったので、実際にパーセプトロンを用いる場合に使用するかもしれない、サンプルのシャッフルについて書きます。  \n",
    "Perceptronアルゴリズムを変更するために、以下の `AdalineSGD`セクションからコードを借りました  \n",
    "（新しい行には ``＃new` \"という行末に印がついています）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "        学習率 (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "        トレーニングデータのトレーニング回数\n",
    "    shuffle : bool (default: True)\n",
    "        Trueの場合、エポックごとにシャッフルする\n",
    "    random_state : int (default: None)\n",
    "        シャッフルと重みの初期化のための、randam_state(シード)を設定\n",
    "\n",
    "    属性\n",
    "    -----------\n",
    "    w_ : 1次元配列\n",
    "        適合後の重み\n",
    "    errors_ : list\n",
    "        各エポックでの誤分類数\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10,\n",
    "                 shuffle=True, random_state=None):  # new\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.shuffle = shuffle  # new\n",
    "        if random_state:  # new\n",
    "            np.random.seed(random_state)  # new\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            if self.shuffle:  # new\n",
    "                X, y = self._shuffle(X, y)  # new\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def _shuffle(self, X, y):  # new\n",
    "        \"\"\"Shuffle training data\"\"\"  # new\n",
    "        r = np.random.permutation(len(y))  # new\n",
    "        return X[r], y[r]  # new\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "210px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
